# A word is worth a thousand vectors

## Slides

* [Talk - Part1 : word2vec] (https://github.com/domarps/Talks-and-Seminars/blob/master/wordIsWorth1000vectors.pdf)
* [Talk - Part2 : Graph-based embedding] (https://github.com/domarps/Talks-and-Seminars/blob/master/TextEmbedding.pdf)

## Blogposts

* [Colah's Blog](http://colah.github.io/)
* [Chris Moody's Blogpost](http://multithreaded.stitchfix.com/blog/2015/03/11/word-is-worth-a-thousand-vectors/)
* [Karpathy's Blog](http://karpathy.github.io/)

## Links
* [word2vec by Mikolov et al. (2013)](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
* [PTE by Tang et al. (2015)](http://arxiv.org/abs/1508.00200)
* [word2vec Parameter Learning Explained by Xin Rong (2014)](http://arxiv.org/abs/1411.2738)

### Resources
* Glove: [http://nlp.stanford.edu/projects/glove/](http://nlp.stanford.edu/projects/glove/)
* TensorFlow: [https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html](https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html)
* DeepLearning4j: [http://deeplearning4j.org/word2vec](http://deeplearning4j.org/word2vec)

## Other neural embedding models
* Bengio (2003) [http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
* Mnih & Hinton (2008) [https://www.cs.toronto.edu/~amnih/papers/hlbl_final.pdf](https://www.cs.toronto.edu/~amnih/papers/hlbl_final.pdf)
* DeepWalk by Perozzi (2014) [http://arxiv.org/abs/1403.6652](http://arxiv.org/abs/1403.6652)
* LINE by Tang et al. (2015) [https://arxiv.org/abs/1503.03578](https://arxiv.org/abs/1503.03578)
